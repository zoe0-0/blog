---
layout: post
title: (AI이노베이션스퀘어_기본과정_Day24) K-Fold와 Stratified K-Fold 교차검증, cross_val_score()와 GridSearchCV
tags:
  - AI이노베이션스퀘어_기본과정
---

<br>

### 교차검증 (Cross Validation)

> 고정된 학습 데이터와 테스트 데이터로 평가하다 보면 테스트 데이터에만 최적의 성능을 발휘하도록 모델을 만드는 경향이 생긴다. 즉, 해당 테스트 데이터에만 과적합(overfitting)되는 학습 모델이 만들어져 다른 테스트 데이터가 들어올 경우에는 성능이 저하된다. 이 문제를 개선하기 위해 교차 검증을 이용해 더 다양한 학습과 평가를 수행한다.

<br>

### K-Fold Cross Validation (k 폴드 교차 검증)

- K번만큼 fold된 각각의 데이터 세트로 학습과 검증을 K번 반복하여 평균 정확도를 구함

```python
from sklearn.datasets import load_iris 
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split
from sklearn.model_selection import cross_val_score
from sklearn.metrics import accuracy_score,classification_report

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
```


```python
from sklearn.model_selection import KFold

iris = load_iris()
features = iris.data  #X.피쳐   (150,4)
label = iris.target   #Y,레이블  (150,)

dt_clf = DecisionTreeClassifier(random_state=11)

kfold = KFold(n_splits=5)
cv_accuracy = []

n_iter=0
#kfold.split(features) : features를 분리하여 학습/검증용 데이터의 인덱스를 반환
for train_index,test_index in kfold.split(features):   
    X_train = features[train_index]
    X_test = features[test_index]
    
    y_train = label[train_index]
    y_test = label[test_index]
    
    #학습 및 예측
    dt_clf.fit(X_train,y_train)
    pred = dt_clf.predict(X_test)
    
    #정확도 측정
    accuracy = round(accuracy_score(y_test,pred),3)
    cv_accuracy.append(accuracy)
    
    n_iter+=1
    
    print(n_iter,'번폴드 교자검증 정확도:',accuracy,'학습데이터의 크기:',X_train.shape[0],'검증데이터의 크기:',X_test.shape[0])
    
print()
print('k폴드 교차검증 평균 정확도',np.mean(cv_accuracy))
```

    1 번폴드 교자검증 정확도: 1.0 학습데이터의 크기: 120 검증데이터의 크기: 30
    2 번폴드 교자검증 정확도: 0.967 학습데이터의 크기: 120 검증데이터의 크기: 30
    3 번폴드 교자검증 정확도: 0.867 학습데이터의 크기: 120 검증데이터의 크기: 30
    4 번폴드 교자검증 정확도: 0.933 학습데이터의 크기: 120 검증데이터의 크기: 30
    5 번폴드 교자검증 정확도: 0.833 학습데이터의 크기: 120 검증데이터의 크기: 30
    
    k폴드 교차검증 평균 정확도 0.9200000000000002

<br>

### Stratified K-Fold Cross Validation

- label이 지나치게 불균형 분포를 이룰 때 레이블(결정 클래스)의 분포를 균일하게 폴드시키는 방식
- 학습데이터와 검증데이터 세트가 가지는 레이블 분포가 유사하도록 폴드시킨다
- 분류(Classification) 모델에서만 가능 (회귀모델 지원x)


```python
iris = load_iris()
iris_df = pd.DataFrame(iris.data,columns=iris.feature_names)
iris_df['label'] = iris.target
iris_df.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }


    .dataframe tbody tr th {
        vertical-align: top;
    }
    
    .dataframe thead th {
        text-align: right;
    }

</style>

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>sepal length (cm)</th>
      <th>sepal width (cm)</th>
      <th>petal length (cm)</th>
      <th>petal width (cm)</th>
      <th>label</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>5.1</td>
      <td>3.5</td>
      <td>1.4</td>
      <td>0.2</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>4.9</td>
      <td>3.0</td>
      <td>1.4</td>
      <td>0.2</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>4.7</td>
      <td>3.2</td>
      <td>1.3</td>
      <td>0.2</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4.6</td>
      <td>3.1</td>
      <td>1.5</td>
      <td>0.2</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5.0</td>
      <td>3.6</td>
      <td>1.4</td>
      <td>0.2</td>
      <td>0</td>
    </tr>
  </tbody>
</table>

</div>

<br>


```python
iris_df['label'].value_counts()
```


    2    50
    1    50
    0    50
    Name: label, dtype: int64

<br>


```python
kfold = KFold(n_splits=5,shuffle=True)  #shuffle과 stratified는 성능이 다르다

n_iter=0
for train_index,test_index in kfold.split(features):    
    n_iter+=1
    label_train = iris_df['label'][train_index]
    label_test = iris_df['label'][test_index]
    print(n_iter,'번 폴드')
    print(label_train.value_counts()) #120개
    print(label_test.value_counts())  #30개
    print()
    
```

    1 번 폴드
    1    42
    2    41
    0    37
    Name: label, dtype: int64
    0    13
    2     9
    1     8
    Name: label, dtype: int64
    
    2 번 폴드
    1    41
    0    41
    2    38
    Name: label, dtype: int64
    2    12
    1     9
    0     9
    Name: label, dtype: int64
    
    3 번 폴드
    0    41
    1    40
    2    39
    Name: label, dtype: int64
    2    11
    1    10
    0     9
    Name: label, dtype: int64
    
    4 번 폴드
    2    41
    0    40
    1    39
    Name: label, dtype: int64
    1    11
    0    10
    2     9
    Name: label, dtype: int64
    
    5 번 폴드
    2    41
    0    41
    1    38
    Name: label, dtype: int64
    1    12
    2     9
    0     9
    Name: label, dtype: int64

<br>


```python
#stratifiedkfold : 레이블의 분포가 균일하게 분리된다.
#원본과 같은 비율로 레이블이 균형 분포를 이룬다
from sklearn.model_selection import StratifiedKFold

skf = StratifiedKFold(n_splits=5)
n_iter=0

for train_index,test_index in skf.split(iris_df,iris_df['label']):
    n_iter+=1
    label_train = iris_df['label'][train_index]
    label_test = iris_df['label'][test_index]
    print(n_iter,'번 폴드')
    print(label_train.value_counts()) #120개
    print(label_test.value_counts())  #30개
    print("-"*50)
```

    1 번 폴드
    2    40
    1    40
    0    40
    Name: label, dtype: int64
    2    10
    1    10
    0    10
    Name: label, dtype: int64
    --------------------------------------------------
    2 번 폴드
    2    40
    1    40
    0    40
    Name: label, dtype: int64
    2    10
    1    10
    0    10
    Name: label, dtype: int64
    --------------------------------------------------
    3 번 폴드
    2    40
    1    40
    0    40
    Name: label, dtype: int64
    2    10
    1    10
    0    10
    Name: label, dtype: int64
    --------------------------------------------------
    4 번 폴드
    2    40
    1    40
    0    40
    Name: label, dtype: int64
    2    10
    1    10
    0    10
    Name: label, dtype: int64
    --------------------------------------------------
    5 번 폴드
    2    40
    1    40
    0    40
    Name: label, dtype: int64
    2    10
    1    10
    0    10
    Name: label, dtype: int64
    --------------------------------------------------

 <br>

```python
#stratifiedkfold를 사용하여 학습 및 예측과 정확도 측정(회귀모델에서는 사용불가능)
skf = StratifiedKFold(n_splits=5)
cv_accuracy = []
n_iter=0

#for train_index,test_index in skf.split(iris_df,iris_df['label']):
for train_index,test_index in skf.split(features,label):
    X_train = features[train_index]
    X_test = features[test_index]
    
    y_train = label[train_index]
    y_test = label[test_index]
    
    #학습 및 예측
    dt_clf.fit(X_train,y_train)
    pred = dt_clf.predict(X_test)
    
    #정확도 측정
    accuracy = round(accuracy_score(y_test,pred),3)
    cv_accuracy.append(accuracy)
    
    n_iter+=1
    print(n_iter,'번폴드 교자검증 정확도:',accuracy,'학습데이터의 크기:',X_train.shape[0],'검증데이터의 크기:',X_test.shape[0])
    
print()
print('k폴드 교차검증 평균 정확도',np.mean(cv_accuracy))
```

    1 번폴드 교자검증 정확도: 0.967 학습데이터의 크기: 120 검증데이터의 크기: 30
    2 번폴드 교자검증 정확도: 0.967 학습데이터의 크기: 120 검증데이터의 크기: 30
    3 번폴드 교자검증 정확도: 0.9 학습데이터의 크기: 120 검증데이터의 크기: 30
    4 번폴드 교자검증 정확도: 0.967 학습데이터의 크기: 120 검증데이터의 크기: 30
    5 번폴드 교자검증 정확도: 1.0 학습데이터의 크기: 120 검증데이터의 크기: 30
    
    k폴드 교차검증 평균 정확도 0.9602

<br>

### cross_val_score( ) : 교차검증을 더 간편하게 

- `cross_val_score()` 함수로 폴드세트 추출, 학습/예측, 평가를 한번에 수행

```markdown
cross_val_score(estimator, X, y=None, *, groups=None, scoring=None, cv=None, n_jobs=None, verbose=0, fit_params=None, pre_dispatch='2*n_jobs', error_score=nan)
```

<br>


```python
iris = load_iris()
X_train,X_test,y_train,y_test = train_test_split(iris.data, iris.target, test_size=0.2,random_state=11) 
print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)

dt_clf = DecisionTreeClassifier(random_state=11)
dt_clf.fit(X_train,y_train) #DecisionTreeClassifier 학습
pred = dt_clf.predict(X_test)
print('정확도:{:.4f}'.format(accuracy_score(y_test,pred)))
print()

#성능지표 => 정확도 / 교차검증세트 => 3개
cv_score = cross_val_score(dt_clf,iris.data,iris.target,scoring='accuracy',cv=3) #3개로 쪼갠다
print('교차검증 정확도',cv_score)
print('교차검증 평균 정확도',cv_score.mean())
```

    (120, 4) (30, 4) (120,) (30,)
    정확도:0.9333
    
    교차검증 정확도 [0.98 0.92 0.98]
    교차검증 평균 정확도 0.96

<br>

### GridSearchCV : 교차검증과 최적의 하이퍼 파리미터 튜닝을 한번에

- 파라미터 집합을 만들어주면 최적의 파라미터 값을 구해주고, 교차검증도 해준다
- `cv_results_`, `best_params_` ,`best_score_` , `best_estimator_`

```markdown
GridSearchCV(
     estimator,  => 분류모델 (Clas sifier 또는 Regressor)
     param_grid,
     *,
     scoring=None,
     n_jobs=None,
     iid='deprecated',
     refit=True,    => 최적의 하이퍼 파리미터를 찾아서, 그 파라미터로 estimator를 학습시킨다 
     cv=None,   => Cross Validation (교차검증)
     verbose=0,
     pre_dispatch='2*n_jobs',
     error_score=nan,
     return_train_score=False,
)
```

<br>


```python
from sklearn.model_selection import GridSearchCV

X_train,X_test,y_train,y_test = train_test_split(iris.data, iris.target, test_size=0.2,random_state=11) 
dt_clf = DecisionTreeClassifier(random_state=11)

#파라미터는 dict 형태로 설정
#이 경우에, 파라미터 적용 횟수 (3*2=6) 
parameters = {'max_depth':[1,2,3],'min_samples_split':[2,3]}
```


```python
grid_tree = GridSearchCV(dt_clf,param_grid=parameters,return_train_score=True)
grid_tree.fit(X_train,y_train)  #param_grid의 하이퍼 파라미터들을 순차적으로 학습/평가
grid_tree.cv_results_

#넘겨준 파라미터 집합을 가지고 조합을 만들어서 최적의 파라미터를 구해준다
# 'params': [{'max_depth': 1, 'min_samples_split': 2},
#           {'max_depth': 1, 'min_samples_split': 3},
#           {'max_depth': 2, 'min_samples_split': 2},
#           {'max_depth': 2, 'min_samples_split': 3},
#           {'max_depth': 3, 'min_samples_split': 2},
#           {'max_depth': 3, 'min_samples_split': 3}],
```


    {'mean_fit_time': array([0.00074749, 0.00064988, 0.00065403, 0.00067401, 0.00069699,
            0.00065255]),
     'std_fit_time': array([1.43010483e-04, 5.35013416e-05, 4.18323453e-05, 5.39854638e-05,
            5.73325252e-05, 5.06114969e-05]),
     'mean_score_time': array([0.00033536, 0.00031748, 0.00028777, 0.00030127, 0.00029559,
            0.00030761]),
     'std_score_time': array([8.27032229e-05, 4.15936501e-05, 8.63193799e-06, 1.87006512e-05,
            1.17822207e-05, 3.34654767e-05]),
     'param_max_depth': masked_array(data=[1, 1, 2, 2, 3, 3],
                  mask=[False, False, False, False, False, False],
            fill_value='?',
                 dtype=object),
     'param_min_samples_split': masked_array(data=[2, 3, 2, 3, 2, 3],
                  mask=[False, False, False, False, False, False],
            fill_value='?',
                 dtype=object),
     'params': [{'max_depth': 1, 'min_samples_split': 2},
      {'max_depth': 1, 'min_samples_split': 3},
      {'max_depth': 2, 'min_samples_split': 2},
      {'max_depth': 2, 'min_samples_split': 3},
      {'max_depth': 3, 'min_samples_split': 2},
      {'max_depth': 3, 'min_samples_split': 3}],
     'split0_test_score': array([0.70833333, 0.70833333, 0.91666667, 0.91666667, 0.91666667,
            0.91666667]),
     'split1_test_score': array([0.66666667, 0.66666667, 0.91666667, 0.91666667, 0.91666667,
            0.91666667]),
     'split2_test_score': array([0.66666667, 0.66666667, 1.        , 1.        , 1.        ,
            1.        ]),
     'split3_test_score': array([0.66666667, 0.66666667, 0.95833333, 0.95833333, 0.95833333,
            0.95833333]),
     'split4_test_score': array([0.66666667, 0.66666667, 0.95833333, 0.95833333, 1.        ,
            1.        ]),
     'mean_test_score': array([0.675     , 0.675     , 0.95      , 0.95      , 0.95833333,
            0.95833333]),
     'std_test_score': array([0.01666667, 0.01666667, 0.03118048, 0.03118048, 0.0372678 ,
            0.0372678 ]),
     'rank_test_score': array([5, 5, 3, 3, 1, 1], dtype=int32),
     'split0_train_score': array([0.66666667, 0.66666667, 0.97916667, 0.97916667, 0.98958333,
            0.98958333]),
     'split1_train_score': array([0.67708333, 0.67708333, 0.97916667, 0.97916667, 0.98958333,
            0.98958333]),
     'split2_train_score': array([0.67708333, 0.67708333, 0.95833333, 0.95833333, 0.96875   ,
            0.96875   ]),
     'split3_train_score': array([0.67708333, 0.67708333, 0.96875   , 0.96875   , 0.98958333,
            0.98958333]),
     'split4_train_score': array([0.67708333, 0.67708333, 0.96875   , 0.96875   , 0.97916667,
            0.97916667]),
     'mean_train_score': array([0.675     , 0.675     , 0.97083333, 0.97083333, 0.98333333,
            0.98333333]),
     'std_train_score': array([0.00416667, 0.00416667, 0.00779512, 0.00779512, 0.00833333,
            0.00833333])}

<br>


```python
# 딕셔너리를 더 편하게 보기 위해 데이터프레임으로 만들어봄
score_df = pd.DataFrame(grid_tree.cv_results_)
score_df[['params','mean_test_score','rank_test_score',
          'split0_train_score','split1_train_score','split2_train_score']]
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }


    .dataframe tbody tr th {
        vertical-align: top;
    }
    
    .dataframe thead th {
        text-align: right;
    }

</style>

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>params</th>
      <th>mean_test_score</th>
      <th>rank_test_score</th>
      <th>split0_train_score</th>
      <th>split1_train_score</th>
      <th>split2_train_score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>{'max_depth': 1, 'min_samples_split': 2}</td>
      <td>0.675000</td>
      <td>5</td>
      <td>0.666667</td>
      <td>0.677083</td>
      <td>0.677083</td>
    </tr>
    <tr>
      <th>1</th>
      <td>{'max_depth': 1, 'min_samples_split': 3}</td>
      <td>0.675000</td>
      <td>5</td>
      <td>0.666667</td>
      <td>0.677083</td>
      <td>0.677083</td>
    </tr>
    <tr>
      <th>2</th>
      <td>{'max_depth': 2, 'min_samples_split': 2}</td>
      <td>0.950000</td>
      <td>3</td>
      <td>0.979167</td>
      <td>0.979167</td>
      <td>0.958333</td>
    </tr>
    <tr>
      <th>3</th>
      <td>{'max_depth': 2, 'min_samples_split': 3}</td>
      <td>0.950000</td>
      <td>3</td>
      <td>0.979167</td>
      <td>0.979167</td>
      <td>0.958333</td>
    </tr>
    <tr>
      <th>4</th>
      <td>{'max_depth': 3, 'min_samples_split': 2}</td>
      <td>0.958333</td>
      <td>1</td>
      <td>0.989583</td>
      <td>0.989583</td>
      <td>0.968750</td>
    </tr>
    <tr>
      <th>5</th>
      <td>{'max_depth': 3, 'min_samples_split': 3}</td>
      <td>0.958333</td>
      <td>1</td>
      <td>0.989583</td>
      <td>0.989583</td>
      <td>0.968750</td>
    </tr>
  </tbody>
</table>

</div>

<br>


```python
#best parameter를 찾을 수 있다
print(grid_tree.best_params_)
print(grid_tree.best_score_)
```

    {'max_depth': 3, 'min_samples_split': 2}
    0.9583333333333333

<br>

```python
pred = grid_tree.predict(X_test)
print('정확도:{:.4f}'.format(accuracy_score(y_test,pred)))
```

    정확도:0.9333

<br>

```python
#best estimator를 찾을 수 도 있다.
#GridSearchCV의 refit으로 이미 학습이 된 estimator 반환
estimator = grid_tree.best_estimator_
print(estimator)
pred = estimator.predict(X_test)
print('정확도:{:.4f}'.format(accuracy_score(y_test,pred)))
```

    DecisionTreeClassifier(max_depth=3, random_state=11)
    정확도:0.9333






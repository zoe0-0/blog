---
layout: post
title: (AI이노베이션스퀘어_기본과정_Day20) 선형회귀(Linear Regression), Scikit-Learn
tags:
  - AI이노베이션스퀘어_기본과정
---

<br>

### 선형회귀 (Linear Regression)

>   [종속 변수](https://ko.wikipedia.org/wiki/독립_변수와_종속_변수) *y*와 한 개 이상의 [독립 변수](https://ko.wikipedia.org/wiki/독립_변수와_종속_변수) (또는 설명 변수) *X*와의 선형 상관 관계를 모델링하는 [회귀분석](https://ko.wikipedia.org/wiki/회귀분석) 기법이다. 한 개의 독립 변수에 기반한 경우에는 [단순 선형 회귀](https://ko.wikipedia.org/wiki/단순_선형_회귀), 둘 이상의 독립 변수에 기반한 경우에는 [다중 선형 회귀](https://ko.wikipedia.org/w/index.php?title=다중_선형_회귀&action=edit&redlink=1)라고 한다.

<br>

### 보스톤 주택가격 예측 Linear Regression, sklearn 사용


```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

df = pd.read_csv('boston_train.csv')
df.head(3)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }


    .dataframe tbody tr th {
        vertical-align: top;
    }
    
    .dataframe thead th {
        text-align: right;
    }

</style>

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>CRIM</th>
      <th>ZN</th>
      <th>INDUS</th>
      <th>NOX</th>
      <th>RM</th>
      <th>AGE</th>
      <th>DIS</th>
      <th>TAX</th>
      <th>PTRATIO</th>
      <th>MEDV</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2.30040</td>
      <td>0.0</td>
      <td>19.58</td>
      <td>0.605</td>
      <td>6.319</td>
      <td>96.1</td>
      <td>2.1000</td>
      <td>403</td>
      <td>14.7</td>
      <td>23.8</td>
    </tr>
    <tr>
      <th>1</th>
      <td>13.35980</td>
      <td>0.0</td>
      <td>18.10</td>
      <td>0.693</td>
      <td>5.887</td>
      <td>94.7</td>
      <td>1.7821</td>
      <td>666</td>
      <td>20.2</td>
      <td>12.7</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.12744</td>
      <td>0.0</td>
      <td>6.91</td>
      <td>0.448</td>
      <td>6.770</td>
      <td>2.9</td>
      <td>5.7209</td>
      <td>233</td>
      <td>17.9</td>
      <td>26.6</td>
    </tr>
  </tbody>
</table>

</div>

<br>


```python
plt.scatter(df['RM'],df['MEDV'],s=10)  #s:사이즈
plt.xlabel('RM')
plt.ylabel('MEDV') #가격
plt.title('Boston Housing Data')
plt.grid()
plt.show()
```

![png](https://raw.githubusercontent.com/zoe0-0/blog/master/images/sklearn_files/sklearn_2_0.png)

<br>

```python
#1차원(단항,피쳐 1개) 회귀모델, scikit-learn 사용
from sklearn.linear_model import LinearRegression

#클래스 인스턴스 생성
lr = LinearRegression()

#입출력 데이터를 설정 : 2차원 배열로 입력
x = df['RM'].values.reshape(-1,1)  #(400,)->(400,1)
y = df['MEDV'].values.reshape(-1,1)

#학습 : x,y를 입력
lr.fit(x,y)

print(lr.coef_)   #회귀계수의 weight 확인
print(lr.intercept_) #회귀계수의 bias
#H(x) = 9.02315014*x + -33.99803804   

#예측 : x만 입력
y_pred = lr.predict(x)

plt.scatter(x,y,c='r',s=10) #원본출력
plt.plot(x,y_pred) #
plt.xlabel('RM')
plt.ylabel('MEDV') 
plt.title('Boston Housing Data')
plt.grid()
plt.show()
```

    [[9.02315014]]
    [-33.99803804]

![png](https://raw.githubusercontent.com/zoe0-0/blog/master/images/sklearn_files/sklearn_3_1.png)

<br>

```python
#list(zip(y,y_pred))  #[(array([18.2]), array([21.00708523])), ....]
```

<br>


```python
#정확도 측정 RMSE(Root Mean Square Error) : 평균 제곱근 오차
from sklearn.metrics import mean_squared_error

mse = mean_squared_error(y,y_pred) #평균 제곱 오차
rmse = np.sqrt(mse) #평균 제곱근 오차
print('RMSE:',rmse)

#R2,R-squared,결정계수 : 1에 가까울 수록 설명력이 높다고(잘 만들어진 모형이라는 평가) 해석  
from sklearn.metrics import r2_score
r2 = r2_score(y,y_pred)
print('r2 score',r2)
```

    RMSE: 6.964958263761021
    r2 score 0.46928062004385107

<br>

```python
#다차원(다항,피쳐가 2개이상) 회귀모델
x = df.iloc[:,:-1]  #9개 컬럼을 피쳐로 사용
y = df.iloc[:,-1:]  #y = df['MEDV'].values.reshape(-1,1) 

#클래스의 인스턴스 생성
lr = LinearRegression()

#학습
lr.fit(x,y)
  
print(lr.coef_)  #weight는 9개
print(lr.intercept_)  #bias는 한개

#예측
y_pred = lr.predict(x)

#시각화
plt.scatter(y_pred,y,c='r',s=10)
plt.xlabel('Predicted Price')
plt.ylabel('Actual Price')
plt.grid()
plt.show()

#정확도 측정
mse = mean_squared_error(y,y_pred)
rmse = np.sqrt(mse)
print('RMSE:',rmse)  #RMSE: 5.753475905312981, 단항 회귀보다 감소 => 정확도 증가

r2 = r2_score(y,y_pred)
print('r2 score',r2)  #r2 score 0.6378499850549992, 단항 회귀보다 증가 => 정확도 증가
```

    [[-1.59072134e-01  4.08534780e-02 -1.18682966e-01 -2.14042031e+01
       6.06293561e+00 -4.40157092e-02 -1.81025024e+00  4.29464930e-04
      -1.08359905e+00]]
    [27.68496713]

![png](https://raw.githubusercontent.com/zoe0-0/blog/master/images/sklearn_files/sklearn_6_1.png)


    RMSE: 5.753475905312981
    r2 score 0.6378499850549992

<br>

